/-
Copyright (c) 2021 S√©bastien Gou√´zel. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: S√©bastien Gou√´zel
-/
import Mathlib.Analysis.Calculus.Deriv.Pow
import Mathlib.Analysis.Calculus.MeanValue

#align_import analysis.calculus.fderiv_symmetric from "leanprover-community/mathlib"@"2c1d8ca2812b64f88992a5294ea3dba144755cd1"

/-!
# Symmetry of the second derivative

We show that, over the reals, the second derivative is symmetric.

The most precise result is `Convex.second_derivative_within_at_symmetric`. It asserts that,
if a function is differentiable inside a convex set `s` with nonempty interior, and has a second
derivative within `s` at a point `x`, then this second derivative at `x` is symmetric. Note that
this result does not require continuity of the first derivative.

The following particular cases of this statement are especially relevant:

`second_derivative_symmetric_of_eventually` asserts that, if a function is differentiable on a
neighborhood of `x`, and has a second derivative at `x`, then this second derivative is symmetric.

`second_derivative_symmetric` asserts that, if a function is differentiable, and has a second
derivative at `x`, then this second derivative is symmetric.

## Implementation note

For the proof, we obtain an asymptotic expansion to order two of `f (x + v + w) - f (x + v)`, by
using the mean value inequality applied to a suitable function along the
segment `[x + v, x + v + w]`. This expansion involves `f'' ‚¨ù w` as we move along a segment directed
by `w` (see `Convex.taylor_approx_two_segment`).

Consider the alternate sum `f (x + v + w) + f x - f (x + v) - f (x + w)`, corresponding to the
values of `f` along a rectangle based at `x` with sides `v` and `w`. One can write it using the two
sides directed by `w`, as `(f (x + v + w) - f (x + v)) - (f (x + w) - f x)`. Together with the
previous asymptotic expansion, one deduces that it equals `f'' v w + o(1)` when `v, w` tends to `0`.
Exchanging the roles of `v` and `w`, one instead gets an asymptotic expansion `f'' w v`, from which
the equality `f'' v w = f'' w v` follows.

In our most general statement, we only assume that `f` is differentiable inside a convex set `s`, so
a few modifications have to be made. Since we don't assume continuity of `f` at `x`, we consider
instead the rectangle based at `x + v + w` with sides `v` and `w`,
in `Convex.isLittleO_alternate_sum_square`, but the argument is essentially the same. It only works
when `v` and `w` both point towards the interior of `s`, to make sure that all the sides of the
rectangle are contained in `s` by convexity. The general case follows by linearity, though.
-/


open Asymptotics Set

open scoped Topology

variable {E F : Type*} [NormedAddCommGroup E] [NormedSpace ‚Ñù E] [NormedAddCommGroup F]
  [NormedSpace ‚Ñù F] {s : Set E} (s_conv : Convex ‚Ñù s) {f : E ‚Üí F} {f' : E ‚Üí E ‚ÜíL[‚Ñù] F}
  {f'' : E ‚ÜíL[‚Ñù] E ‚ÜíL[‚Ñù] F} (hf : ‚àÄ x ‚àà interior s, HasFDerivAt f (f' x) x) {x : E} (xs : x ‚àà s)
  (hx : HasFDerivWithinAt f' f'' (interior s) x)

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one can
Taylor-expand to order two the function `f` on the segment `[x + h v, x + h (v + w)]`, giving a
bilinear estimate for `f (x + hv + hw) - f (x + hv)` in terms of `f' w` and of `f'' ‚¨ù w`, up to
`o(h^2)`.

This is a technical statement used to show that the second derivative is symmetric. -/
theorem Convex.taylor_approx_two_segment {v w : E} (hv : x + v ‚àà interior s)
    (hw : x + v + w ‚àà interior s) :
    (fun h : ‚Ñù => f (x + h ‚Ä¢ v + h ‚Ä¢ w)
        - f (x + h ‚Ä¢ v) - h ‚Ä¢ f' x w - h ^ 2 ‚Ä¢ f'' v w - (h ^ 2 / 2) ‚Ä¢ f'' w w) =o[ùìù[>] 0]
      fun h => h ^ 2 := by
  -- it suffices to check that the expression is bounded by `Œµ * ((‚Äñv‚Äñ + ‚Äñw‚Äñ) * ‚Äñw‚Äñ) * h^2` for
  -- small enough `h`, for any positive `Œµ`.
  refine' IsLittleO.trans_isBigO
    (isLittleO_iff.2 fun Œµ Œµpos => _) (isBigO_const_mul_self ((‚Äñv‚Äñ + ‚Äñw‚Äñ) * ‚Äñw‚Äñ) _ _)
  -- consider a ball of radius `Œ¥` around `x` in which the Taylor approximation for `f''` is
  -- good up to `Œ¥`.
  rw [HasFDerivWithinAt, hasFDerivAtFilter_iff_isLittleO, isLittleO_iff] at hx
  rcases Metric.mem_nhdsWithin_iff.1 (hx Œµpos) with ‚ü®Œ¥, Œ¥pos, sŒ¥‚ü©
  have E1 : ‚àÄ·∂† h in ùìù[>] (0 : ‚Ñù), h * (‚Äñv‚Äñ + ‚Äñw‚Äñ) < Œ¥ := by
    have : Filter.Tendsto (fun h => h * (‚Äñv‚Äñ + ‚Äñw‚Äñ)) (ùìù[>] (0 : ‚Ñù)) (ùìù (0 * (‚Äñv‚Äñ + ‚Äñw‚Äñ))) :=
      (continuous_id.mul continuous_const).continuousWithinAt
    apply (tendsto_order.1 this).2 Œ¥
    simpa only [zero_mul] using Œ¥pos
  have E2 : ‚àÄ·∂† h in ùìù[>] (0 : ‚Ñù), (h : ‚Ñù) < 1 :=
    mem_nhdsWithin_Ioi_iff_exists_Ioo_subset.2
      ‚ü®(1 : ‚Ñù), by simp only [mem_Ioi, zero_lt_one], fun x hx => hx.2‚ü©
  filter_upwards [E1, E2, self_mem_nhdsWithin] with h hŒ¥ h_lt_1 hpos
  -- we consider `h` small enough that all points under consideration belong to this ball,
  -- and also with `0 < h < 1`.
  replace hpos : 0 < h := hpos
  have xt_mem : ‚àÄ t ‚àà Icc (0 : ‚Ñù) 1, x + h ‚Ä¢ v + (t * h) ‚Ä¢ w ‚àà interior s := by
    intro t ht
    have : x + h ‚Ä¢ v ‚àà interior s := s_conv.add_smul_mem_interior xs hv ‚ü®hpos, h_lt_1.le‚ü©
    rw [‚Üê smul_smul]
    apply s_conv.interior.add_smul_mem this _ ht
    rw [add_assoc] at hw
    rw [add_assoc, ‚Üê smul_add]
    exact s_conv.add_smul_mem_interior xs hw ‚ü®hpos, h_lt_1.le‚ü©
  -- define a function `g` on `[0,1]` (identified with `[v, v + w]`) such that `g 1 - g 0` is the
  -- quantity to be estimated. We will check that its derivative is given by an explicit
  -- expression `g'`, that we can bound. Then the desired bound for `g 1 - g 0` follows from the
  -- mean value inequality.
  let g t :=
    f (x + h ‚Ä¢ v + (t * h) ‚Ä¢ w) - (t * h) ‚Ä¢ f' x w - (t * h ^ 2) ‚Ä¢ f'' v w -
      ((t * h) ^ 2 / 2) ‚Ä¢ f'' w w
  set g' := fun t =>
    f' (x + h ‚Ä¢ v + (t * h) ‚Ä¢ w) (h ‚Ä¢ w) - h ‚Ä¢ f' x w - h ^ 2 ‚Ä¢ f'' v w - (t * h ^ 2) ‚Ä¢ f'' w w
    with hg'
  -- check that `g'` is the derivative of `g`, by a straightforward computation
  have g_deriv : ‚àÄ t ‚àà Icc (0 : ‚Ñù) 1, HasDerivWithinAt g (g' t) (Icc 0 1) t := by
    intro t ht
    apply_rules [HasDerivWithinAt.sub, HasDerivWithinAt.add]
    ¬∑ refine' (hf _ _).comp_hasDerivWithinAt _ _
      ¬∑ exact xt_mem t ht
      apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.const_add, HasDerivAt.smul_const,
        hasDerivAt_mul_const]
    ¬∑ apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_mul_const]
    ¬∑ apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_mul_const]
    ¬∑ suffices H : HasDerivWithinAt (fun u => ((u * h) ^ 2 / 2) ‚Ä¢ f'' w w)
          ((((2 : ‚Ñï) : ‚Ñù) * (t * h) ^ (2 - 1) * (1 * h) / 2) ‚Ä¢ f'' w w) (Icc 0 1) t
      ¬∑ convert H using 2
        ring
      apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_id',
        HasDerivAt.pow, HasDerivAt.mul_const]
  -- check that `g'` is uniformly bounded, with a suitable bound `Œµ * ((‚Äñv‚Äñ + ‚Äñw‚Äñ) * ‚Äñw‚Äñ) * h^2`.
  have g'_bound : ‚àÄ t ‚àà Ico (0 : ‚Ñù) 1, ‚Äñg' t‚Äñ ‚â§ Œµ * ((‚Äñv‚Äñ + ‚Äñw‚Äñ) * ‚Äñw‚Äñ) * h ^ 2 := by
    intro t ht
    have I : ‚Äñh ‚Ä¢ v + (t * h) ‚Ä¢ w‚Äñ ‚â§ h * (‚Äñv‚Äñ + ‚Äñw‚Äñ) :=
      calc
        ‚Äñh ‚Ä¢ v + (t * h) ‚Ä¢ w‚Äñ ‚â§ ‚Äñh ‚Ä¢ v‚Äñ + ‚Äñ(t * h) ‚Ä¢ w‚Äñ := norm_add_le _ _
        _ = h * ‚Äñv‚Äñ + t * (h * ‚Äñw‚Äñ) := by
          simp only [norm_smul, Real.norm_eq_abs, hpos.le, abs_of_nonneg, abs_mul, ht.left,
            mul_assoc]
        _ ‚â§ h * ‚Äñv‚Äñ + 1 * (h * ‚Äñw‚Äñ) := by gcongr; exact ht.2.le
        _ = h * (‚Äñv‚Äñ + ‚Äñw‚Äñ) := by ring
    calc
      ‚Äñg' t‚Äñ = ‚Äñ(f' (x + h ‚Ä¢ v + (t * h) ‚Ä¢ w) - f' x - f'' (h ‚Ä¢ v + (t * h) ‚Ä¢ w)) (h ‚Ä¢ w)‚Äñ := by
        rw [hg']
        have : h * (t * h) = t * (h * h) := by ring
        simp only [ContinuousLinearMap.coe_sub', ContinuousLinearMap.map_add, pow_two,
          ContinuousLinearMap.add_apply, Pi.smul_apply, smul_sub, smul_add, smul_smul, ‚Üê sub_sub,
          ContinuousLinearMap.coe_smul', Pi.sub_apply, ContinuousLinearMap.map_smul, this]
      _ ‚â§ ‚Äñf' (x + h ‚Ä¢ v + (t * h) ‚Ä¢ w) - f' x - f'' (h ‚Ä¢ v + (t * h) ‚Ä¢ w)‚Äñ * ‚Äñh ‚Ä¢ w‚Äñ :=
        (ContinuousLinearMap.le_opNorm _ _)
      _ ‚â§ Œµ * ‚Äñh ‚Ä¢ v + (t * h) ‚Ä¢ w‚Äñ * ‚Äñh ‚Ä¢ w‚Äñ := by
        apply mul_le_mul_of_nonneg_right _ (norm_nonneg _)
        have H : x + h ‚Ä¢ v + (t * h) ‚Ä¢ w ‚àà Metric.ball x Œ¥ ‚à© interior s := by
          refine' ‚ü®_, xt_mem t ‚ü®ht.1, ht.2.le‚ü©‚ü©
          rw [add_assoc, add_mem_ball_iff_norm]
          exact I.trans_lt hŒ¥
        simpa only [mem_setOf_eq, add_assoc x, add_sub_cancel'] using sŒ¥ H
      _ ‚â§ Œµ * (‚Äñh ‚Ä¢ v‚Äñ + ‚Äñh ‚Ä¢ w‚Äñ) * ‚Äñh ‚Ä¢ w‚Äñ := by
        gcongr
        apply (norm_add_le _ _).trans
        gcongr
        simp only [norm_smul, Real.norm_eq_abs, abs_mul, abs_of_nonneg, ht.1, hpos.le, mul_assoc]
        exact mul_le_of_le_one_left (mul_nonneg hpos.le (norm_nonneg _)) ht.2.le
      _ = Œµ * ((‚Äñv‚Äñ + ‚Äñw‚Äñ) * ‚Äñw‚Äñ) * h ^ 2 := by
        simp only [norm_smul, Real.norm_eq_abs, abs_mul, abs_of_nonneg, hpos.le]; ring
  -- conclude using the mean value inequality
  have I : ‚Äñg 1 - g 0‚Äñ ‚â§ Œµ * ((‚Äñv‚Äñ + ‚Äñw‚Äñ) * ‚Äñw‚Äñ) * h ^ 2 := by
    simpa only [mul_one, sub_zero] using
      norm_image_sub_le_of_norm_deriv_le_segment' g_deriv g'_bound 1 (right_mem_Icc.2 zero_le_one)
  convert I using 1
  ¬∑ congr 1
    simp only [Nat.one_ne_zero, add_zero, one_mul, zero_div, zero_mul, sub_zero,
      zero_smul, Ne.def, not_false_iff, bit0_eq_zero, zero_pow]
    abel
  ¬∑ simp only [Real.norm_eq_abs, abs_mul, add_nonneg (norm_nonneg v) (norm_nonneg w), abs_of_nonneg,
      hpos.le, mul_assoc, pow_bit0_abs, norm_nonneg, abs_pow]
#align convex.taylor_approx_two_segment Convex.taylor_approx_two_segment

/-- One can get `f'' v w` as the limit of `h ^ (-2)` times the alternate sum of the values of `f`
along the vertices of a quadrilateral with sides `h v` and `h w` based at `x`.
In a setting where `f` is not guaranteed to be continuous at `f`, we can still
get this if we use a quadrilateral based at `h v + h w`. -/
theorem Convex.isLittleO_alternate_sum_square {v w : E} (h4v : x + (4 : ‚Ñù) ‚Ä¢ v ‚àà interior s)
    (h4w : x + (4 : ‚Ñù) ‚Ä¢ w ‚àà interior s) :
    (fun h : ‚Ñù => f (x + h ‚Ä¢ (2 ‚Ä¢ v + 2 ‚Ä¢ w)) + f (x + h ‚Ä¢ (v + w))
        - f (x + h ‚Ä¢ (2 ‚Ä¢ v + w)) - f (x + h ‚Ä¢ (v + 2 ‚Ä¢ w)) - h ^ 2 ‚Ä¢ f'' v w) =o[ùìù[>] 0]
      fun h => h ^ 2 := by
  have A : (1 : ‚Ñù) / 2 ‚àà Ioc (0 : ‚Ñù) 1 := ‚ü®by norm_num, by norm_num‚ü©
  have B : (1 : ‚Ñù) / 2 ‚àà Icc (0 : ‚Ñù) 1 := ‚ü®by norm_num, by norm_num‚ü©
  have C : ‚àÄ w : E, (2 : ‚Ñù) ‚Ä¢ w = 2 ‚Ä¢ w := fun w => by simp only [two_smul]
  have h2v2w : x + (2 : ‚Ñù) ‚Ä¢ v + (2 : ‚Ñù) ‚Ä¢ w ‚àà interior s := by
    convert s_conv.interior.add_smul_sub_mem h4v h4w B using 1
    simp only [smul_sub, smul_smul, one_div, add_sub_add_left_eq_sub, mul_add, add_smul]
    norm_num
    simp only [show (4 : ‚Ñù) = (2 : ‚Ñù) + (2 : ‚Ñù) by norm_num, _root_.add_smul]
    abel
  have h2vww : x + (2 ‚Ä¢ v + w) + w ‚àà interior s := by
    convert h2v2w using 1
    simp only [two_smul]
    abel
  have h2v : x + (2 : ‚Ñù) ‚Ä¢ v ‚àà interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4v A using 1
    simp only [smul_smul, one_div, add_sub_cancel', add_right_inj]
    norm_num
  have h2w : x + (2 : ‚Ñù) ‚Ä¢ w ‚àà interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4w A using 1
    simp only [smul_smul, one_div, add_sub_cancel', add_right_inj]
    norm_num
  have hvw : x + (v + w) ‚àà interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h2v2w A using 1
    simp only [smul_smul, one_div, add_sub_cancel', add_right_inj, smul_add, smul_sub]
    norm_num
    abel
  have h2vw : x + (2 ‚Ä¢ v + w) ‚àà interior s := by
    convert s_conv.interior.add_smul_sub_mem h2v h2v2w B using 1
    simp only [smul_add, smul_sub, smul_smul, ‚Üê C]
    norm_num
    abel
  have hvww : x + (v + w) + w ‚àà interior s := by
    convert s_conv.interior.add_smul_sub_mem h2w h2v2w B using 1
    rw [one_div, add_sub_add_right_eq_sub, add_sub_cancel', inv_smul_smul‚ÇÄ two_ne_zero, two_smul]
    abel
  have TA1 := s_conv.taylor_approx_two_segment hf xs hx h2vw h2vww
  have TA2 := s_conv.taylor_approx_two_segment hf xs hx hvw hvww
  convert TA1.sub TA2 using 1
  ext h
  simp only [two_smul, smul_add, ‚Üê add_assoc, ContinuousLinearMap.map_add,
    ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul',
    ContinuousLinearMap.map_smul]
  abel
#align convex.is_o_alternate_sum_square Convex.isLittleO_alternate_sum_square

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one
has `f'' v w = f'' w v`. Superseded by `Convex.second_derivative_within_at_symmetric`, which
removes the assumption that `v` and `w` point inside `s`. -/
theorem Convex.second_derivative_within_at_symmetric_of_mem_interior {v w : E}
    (h4v : x + (4 : ‚Ñù) ‚Ä¢ v ‚àà interior s) (h4w : x + (4 : ‚Ñù) ‚Ä¢ w ‚àà interior s) :
    f'' w v = f'' v w := by
  have A : (fun h : ‚Ñù => h ^ 2 ‚Ä¢ (f'' w v - f'' v w)) =o[ùìù[>] 0] fun h => h ^ 2 := by
    convert (s_conv.isLittleO_alternate_sum_square hf xs hx h4v h4w).sub
      (s_conv.isLittleO_alternate_sum_square hf xs hx h4w h4v) using 1
    ext h
    simp only [add_comm, smul_add, smul_sub]
    abel
  have B : (fun _ : ‚Ñù => f'' w v - f'' v w) =o[ùìù[>] 0] fun _ => (1 : ‚Ñù) := by
    have : (fun h : ‚Ñù => 1 / h ^ 2) =O[ùìù[>] 0] fun h => 1 / h ^ 2 := isBigO_refl _ _
    have C := this.smul_isLittleO A
    apply C.congr' _ _
    ¬∑ filter_upwards [self_mem_nhdsWithin]
      intro h (hpos : 0 < h)
      rw [‚Üê one_smul ‚Ñù (f'' w v - f'' v w), smul_smul, smul_smul]
      congr 1
      field_simp [LT.lt.ne' hpos]
    ¬∑ filter_upwards [self_mem_nhdsWithin] with h (hpos : 0 < h)
      field_simp [LT.lt.ne' hpos, SMul.smul]
  simpa only [sub_eq_zero] using isLittleO_const_const_iff.1 B
#align convex.second_derivative_within_at_symmetric_of_mem_interior Convex.second_derivative_within_at_symmetric_of_mem_interior

/-- If a function is differentiable inside a convex set with nonempty interior, and has a second
derivative at a point of this convex set, then this second derivative is symmetric. -/
theorem Convex.second_derivative_within_at_symmetric {s : Set E} (s_conv : Convex ‚Ñù s)
    (hne : (interior s).Nonempty) {f : E ‚Üí F} {f' : E ‚Üí E ‚ÜíL[‚Ñù] F} {f'' : E ‚ÜíL[‚Ñù] E ‚ÜíL[‚Ñù] F}
    (hf : ‚àÄ x ‚àà interior s, HasFDerivAt f (f' x) x) {x : E} (xs : x ‚àà s)
    (hx : HasFDerivWithinAt f' f'' (interior s) x) (v w : E) : f'' v w = f'' w v := by
  /- we work around a point `x + 4 z` in the interior of `s`. For any vector `m`,
    then `x + 4 (z + t m)` also belongs to the interior of `s` for small enough `t`. This means that
    we will be able to apply `second_derivative_within_at_symmetric_of_mem_interior` to show
    that `f''` is symmetric, after cancelling all the contributions due to `z`. -/
  rcases hne with ‚ü®y, hy‚ü©
  obtain ‚ü®z, hz‚ü© : ‚àÉ z, z = ((1 : ‚Ñù) / 4) ‚Ä¢ (y - x) := ‚ü®((1 : ‚Ñù) / 4) ‚Ä¢ (y - x), rfl‚ü©
  have A : ‚àÄ m : E, Filter.Tendsto (fun t : ‚Ñù => x + (4 : ‚Ñù) ‚Ä¢ (z + t ‚Ä¢ m)) (ùìù 0) (ùìù y) := by
    intro m
    have : x + (4 : ‚Ñù) ‚Ä¢ (z + (0 : ‚Ñù) ‚Ä¢ m) = y := by simp [hz]
    rw [‚Üê this]
    refine' tendsto_const_nhds.add <| tendsto_const_nhds.smul <| tendsto_const_nhds.add _
    exact continuousAt_id.smul continuousAt_const
  have B : ‚àÄ m : E, ‚àÄ·∂† t in ùìù[>] (0 : ‚Ñù), x + (4 : ‚Ñù) ‚Ä¢ (z + t ‚Ä¢ m) ‚àà interior s := by
    intro m
    apply nhdsWithin_le_nhds
    apply A m
    rw [mem_interior_iff_mem_nhds] at hy
    exact interior_mem_nhds.2 hy
  -- we choose `t m > 0` such that `x + 4 (z + (t m) m)` belongs to the interior of `s`, for any
  -- vector `m`.
  choose t ts tpos using fun m => ((B m).and self_mem_nhdsWithin).exists
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z`
  -- and `z + (t m) m`, we deduce that `f'' m z = f'' z m` for all `m`.
  have C : ‚àÄ m : E, f'' m z = f'' z m := by
    intro m
    have : f'' (z + t m ‚Ä¢ m) (z + t 0 ‚Ä¢ (0 : E)) = f'' (z + t 0 ‚Ä¢ (0 : E)) (z + t m ‚Ä¢ m) :=
      s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts 0) (ts m)
    simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.map_smul, add_right_inj,
      ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul', add_zero,
      ContinuousLinearMap.zero_apply, smul_zero, ContinuousLinearMap.map_zero] at this
    exact smul_right_injective F (tpos m).ne' this
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z + (t v) v`
  -- and `z + (t w) w`, we deduce that `f'' v w = f'' w v`. Cross terms involving `z` can be
  -- eliminated thanks to the fact proved above that `f'' m z = f'' z m`.
  have : f'' (z + t v ‚Ä¢ v) (z + t w ‚Ä¢ w) = f'' (z + t w ‚Ä¢ w) (z + t v ‚Ä¢ v) :=
    s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts w) (ts v)
  simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.map_smul, smul_add, smul_smul,
    ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul', C] at this
  rw [add_assoc, add_assoc, add_right_inj, add_left_comm, add_right_inj, add_right_inj, mul_comm]
    at this
  apply smul_right_injective F _ this
  simp [(tpos v).ne', (tpos w).ne']
#align convex.second_derivative_within_at_symmetric Convex.second_derivative_within_at_symmetric

/-- If a function is differentiable around `x`, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric_of_eventually {f : E ‚Üí F} {f' : E ‚Üí E ‚ÜíL[‚Ñù] F}
    {f'' : E ‚ÜíL[‚Ñù] E ‚ÜíL[‚Ñù] F} (hf : ‚àÄ·∂† y in ùìù x, HasFDerivAt f (f' y) y) (hx : HasFDerivAt f' f'' x)
    (v w : E) : f'' v w = f'' w v := by
  rcases Metric.mem_nhds_iff.1 hf with ‚ü®Œµ, Œµpos, hŒµ‚ü©
  have A : (interior (Metric.ball x Œµ)).Nonempty := by
    rwa [Metric.isOpen_ball.interior_eq, Metric.nonempty_ball]
  exact
    Convex.second_derivative_within_at_symmetric (convex_ball x Œµ) A
      (fun y hy => hŒµ (interior_subset hy)) (Metric.mem_ball_self Œµpos) hx.hasFDerivWithinAt v w
#align second_derivative_symmetric_of_eventually second_derivative_symmetric_of_eventually

/-- If a function is differentiable, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric {f : E ‚Üí F} {f' : E ‚Üí E ‚ÜíL[‚Ñù] F} {f'' : E ‚ÜíL[‚Ñù] E ‚ÜíL[‚Ñù] F}
    (hf : ‚àÄ y, HasFDerivAt f (f' y) y) (hx : HasFDerivAt f' f'' x) (v w : E) : f'' v w = f'' w v :=
  second_derivative_symmetric_of_eventually (Filter.eventually_of_forall hf) hx v w
#align second_derivative_symmetric second_derivative_symmetric
