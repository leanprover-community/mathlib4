/-
Copyright (c) 2021 SÃ©bastien GouÃ«zel. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: SÃ©bastien GouÃ«zel
-/
import Mathlib.Analysis.Calculus.Deriv.Pow
import Mathlib.Analysis.Calculus.MeanValue

#align_import analysis.calculus.fderiv_symmetric from "leanprover-community/mathlib"@"2c1d8ca2812b64f88992a5294ea3dba144755cd1"

/-!
# Symmetry of the second derivative

We show that, over the reals, the second derivative is symmetric.

The most precise result is `Convex.second_derivative_within_at_symmetric`. It asserts that,
if a function is differentiable inside a convex set `s` with nonempty interior, and has a second
derivative within `s` at a point `x`, then this second derivative at `x` is symmetric. Note that
this result does not require continuity of the first derivative.

The following particular cases of this statement are especially relevant:

`second_derivative_symmetric_of_eventually` asserts that, if a function is differentiable on a
neighborhood of `x`, and has a second derivative at `x`, then this second derivative is symmetric.

`second_derivative_symmetric` asserts that, if a function is differentiable, and has a second
derivative at `x`, then this second derivative is symmetric.

## Implementation note

For the proof, we obtain an asymptotic expansion to order two of `f (x + v + w) - f (x + v)`, by
using the mean value inequality applied to a suitable function along the
segment `[x + v, x + v + w]`. This expansion involves `f'' â¬ w` as we move along a segment directed
by `w` (see `Convex.taylor_approx_two_segment`).

Consider the alternate sum `f (x + v + w) + f x - f (x + v) - f (x + w)`, corresponding to the
values of `f` along a rectangle based at `x` with sides `v` and `w`. One can write it using the two
sides directed by `w`, as `(f (x + v + w) - f (x + v)) - (f (x + w) - f x)`. Together with the
previous asymptotic expansion, one deduces that it equals `f'' v w + o(1)` when `v, w` tends to `0`.
Exchanging the roles of `v` and `w`, one instead gets an asymptotic expansion `f'' w v`, from which
the equality `f'' v w = f'' w v` follows.

In our most general statement, we only assume that `f` is differentiable inside a convex set `s`, so
a few modifications have to be made. Since we don't assume continuity of `f` at `x`, we consider
instead the rectangle based at `x + v + w` with sides `v` and `w`,
in `Convex.isLittleO_alternate_sum_square`, but the argument is essentially the same. It only works
when `v` and `w` both point towards the interior of `s`, to make sure that all the sides of the
rectangle are contained in `s` by convexity. The general case follows by linearity, though.
-/


open Asymptotics Set

open scoped Topology

variable {E F : Type*} [NormedAddCommGroup E] [NormedSpace â„ E] [NormedAddCommGroup F]
  [NormedSpace â„ F] {s : Set E} (s_conv : Convex â„ s) {f : E â†’ F} {f' : E â†’ E â†’L[â„] F}
  {f'' : E â†’L[â„] E â†’L[â„] F} (hf : âˆ€ x âˆˆ interior s, HasFDerivAt f (f' x) x) {x : E} (xs : x âˆˆ s)
  (hx : HasFDerivWithinAt f' f'' (interior s) x)

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one can
Taylor-expand to order two the function `f` on the segment `[x + h v, x + h (v + w)]`, giving a
bilinear estimate for `f (x + hv + hw) - f (x + hv)` in terms of `f' w` and of `f'' â¬ w`, up to
`o(h^2)`.

This is a technical statement used to show that the second derivative is symmetric. -/
theorem Convex.taylor_approx_two_segment {v w : E} (hv : x + v âˆˆ interior s)
    (hw : x + v + w âˆˆ interior s) :
    (fun h : â„ => f (x + h â€¢ v + h â€¢ w)
        - f (x + h â€¢ v) - h â€¢ f' x w - h ^ 2 â€¢ f'' v w - (h ^ 2 / 2) â€¢ f'' w w) =o[ğ“[>] 0]
      fun h => h ^ 2 := by
  -- it suffices to check that the expression is bounded by `Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h^2` for
  -- small enough `h`, for any positive `Îµ`.
  refine IsLittleO.trans_isBigO
    (isLittleO_iff.2 fun Îµ Îµpos => ?_) (isBigO_const_mul_self ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) _ _)
  -- consider a ball of radius `Î´` around `x` in which the Taylor approximation for `f''` is
  -- good up to `Î´`.
  rw [HasFDerivWithinAt, hasFDerivAtFilter_iff_isLittleO, isLittleO_iff] at hx
  rcases Metric.mem_nhdsWithin_iff.1 (hx Îµpos) with âŸ¨Î´, Î´pos, sÎ´âŸ©
  have E1 : âˆ€á¶  h in ğ“[>] (0 : â„), h * (â€–vâ€– + â€–wâ€–) < Î´ := by
    have : Filter.Tendsto (fun h => h * (â€–vâ€– + â€–wâ€–)) (ğ“[>] (0 : â„)) (ğ“ (0 * (â€–vâ€– + â€–wâ€–))) :=
      (continuous_id.mul continuous_const).continuousWithinAt
    apply (tendsto_order.1 this).2 Î´
    simpa only [zero_mul] using Î´pos
  have E2 : âˆ€á¶  h in ğ“[>] (0 : â„), (h : â„) < 1 :=
    mem_nhdsWithin_Ioi_iff_exists_Ioo_subset.2
      âŸ¨(1 : â„), by simp only [mem_Ioi, zero_lt_one], fun x hx => hx.2âŸ©
  filter_upwards [E1, E2, self_mem_nhdsWithin] with h hÎ´ h_lt_1 hpos
  -- we consider `h` small enough that all points under consideration belong to this ball,
  -- and also with `0 < h < 1`.
  replace hpos : 0 < h := hpos
  have xt_mem : âˆ€ t âˆˆ Icc (0 : â„) 1, x + h â€¢ v + (t * h) â€¢ w âˆˆ interior s := by
    intro t ht
    have : x + h â€¢ v âˆˆ interior s := s_conv.add_smul_mem_interior xs hv âŸ¨hpos, h_lt_1.leâŸ©
    rw [â† smul_smul]
    apply s_conv.interior.add_smul_mem this _ ht
    rw [add_assoc] at hw
    rw [add_assoc, â† smul_add]
    exact s_conv.add_smul_mem_interior xs hw âŸ¨hpos, h_lt_1.leâŸ©
  -- define a function `g` on `[0,1]` (identified with `[v, v + w]`) such that `g 1 - g 0` is the
  -- quantity to be estimated. We will check that its derivative is given by an explicit
  -- expression `g'`, that we can bound. Then the desired bound for `g 1 - g 0` follows from the
  -- mean value inequality.
  let g t :=
    f (x + h â€¢ v + (t * h) â€¢ w) - (t * h) â€¢ f' x w - (t * h ^ 2) â€¢ f'' v w -
      ((t * h) ^ 2 / 2) â€¢ f'' w w
  set g' := fun t =>
    f' (x + h â€¢ v + (t * h) â€¢ w) (h â€¢ w) - h â€¢ f' x w - h ^ 2 â€¢ f'' v w - (t * h ^ 2) â€¢ f'' w w
    with hg'
  -- check that `g'` is the derivative of `g`, by a straightforward computation
  have g_deriv : âˆ€ t âˆˆ Icc (0 : â„) 1, HasDerivWithinAt g (g' t) (Icc 0 1) t := by
    intro t ht
    apply_rules [HasDerivWithinAt.sub, HasDerivWithinAt.add]
    Â· refine (hf _ ?_).comp_hasDerivWithinAt _ ?_
      Â· exact xt_mem t ht
      apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.const_add, HasDerivAt.smul_const,
        hasDerivAt_mul_const]
    Â· apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_mul_const]
    Â· apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_mul_const]
    Â· suffices H : HasDerivWithinAt (fun u => ((u * h) ^ 2 / 2) â€¢ f'' w w)
          ((((2 : â„•) : â„) * (t * h) ^ (2 - 1) * (1 * h) / 2) â€¢ f'' w w) (Icc 0 1) t by
        convert H using 2
        ring
      apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_id',
        HasDerivAt.pow, HasDerivAt.mul_const]
  -- check that `g'` is uniformly bounded, with a suitable bound `Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h^2`.
  have g'_bound : âˆ€ t âˆˆ Ico (0 : â„) 1, â€–g' tâ€– â‰¤ Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h ^ 2 := by
    intro t ht
    have I : â€–h â€¢ v + (t * h) â€¢ wâ€– â‰¤ h * (â€–vâ€– + â€–wâ€–) :=
      calc
        â€–h â€¢ v + (t * h) â€¢ wâ€– â‰¤ â€–h â€¢ vâ€– + â€–(t * h) â€¢ wâ€– := norm_add_le _ _
        _ = h * â€–vâ€– + t * (h * â€–wâ€–) := by
          simp only [norm_smul, Real.norm_eq_abs, hpos.le, abs_of_nonneg, abs_mul, ht.left,
            mul_assoc]
        _ â‰¤ h * â€–vâ€– + 1 * (h * â€–wâ€–) := by gcongr; exact ht.2.le
        _ = h * (â€–vâ€– + â€–wâ€–) := by ring
    calc
      â€–g' tâ€– = â€–(f' (x + h â€¢ v + (t * h) â€¢ w) - f' x - f'' (h â€¢ v + (t * h) â€¢ w)) (h â€¢ w)â€– := by
        rw [hg']
        have : h * (t * h) = t * (h * h) := by ring
        simp only [ContinuousLinearMap.coe_sub', ContinuousLinearMap.map_add, pow_two,
          ContinuousLinearMap.add_apply, Pi.smul_apply, smul_sub, smul_add, smul_smul, â† sub_sub,
          ContinuousLinearMap.coe_smul', Pi.sub_apply, ContinuousLinearMap.map_smul, this]
      _ â‰¤ â€–f' (x + h â€¢ v + (t * h) â€¢ w) - f' x - f'' (h â€¢ v + (t * h) â€¢ w)â€– * â€–h â€¢ wâ€– :=
        (ContinuousLinearMap.le_opNorm _ _)
      _ â‰¤ Îµ * â€–h â€¢ v + (t * h) â€¢ wâ€– * â€–h â€¢ wâ€– := by
        apply mul_le_mul_of_nonneg_right _ (norm_nonneg _)
        have H : x + h â€¢ v + (t * h) â€¢ w âˆˆ Metric.ball x Î´ âˆ© interior s := by
          refine âŸ¨?_, xt_mem t âŸ¨ht.1, ht.2.leâŸ©âŸ©
          rw [add_assoc, add_mem_ball_iff_norm]
          exact I.trans_lt hÎ´
        simpa only [mem_setOf_eq, add_assoc x, add_sub_cancel_left] using sÎ´ H
      _ â‰¤ Îµ * (â€–h â€¢ vâ€– + â€–h â€¢ wâ€–) * â€–h â€¢ wâ€– := by
        gcongr
        apply (norm_add_le _ _).trans
        gcongr
        simp only [norm_smul, Real.norm_eq_abs, abs_mul, abs_of_nonneg, ht.1, hpos.le, mul_assoc]
        exact mul_le_of_le_one_left (mul_nonneg hpos.le (norm_nonneg _)) ht.2.le
      _ = Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h ^ 2 := by
        simp only [norm_smul, Real.norm_eq_abs, abs_mul, abs_of_nonneg, hpos.le]; ring
  -- conclude using the mean value inequality
  have I : â€–g 1 - g 0â€– â‰¤ Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h ^ 2 := by
    simpa only [mul_one, sub_zero] using
      norm_image_sub_le_of_norm_deriv_le_segment' g_deriv g'_bound 1 (right_mem_Icc.2 zero_le_one)
  convert I using 1
  Â· congr 1
    simp only [g, Nat.one_ne_zero, add_zero, one_mul, zero_div, zero_mul, sub_zero,
      zero_smul, Ne, not_false_iff, bit0_eq_zero, zero_pow]
    abel
  Â· simp only [Real.norm_eq_abs, abs_mul, add_nonneg (norm_nonneg v) (norm_nonneg w), abs_of_nonneg,
      hpos.le, mul_assoc, norm_nonneg, abs_pow]
#align convex.taylor_approx_two_segment Convex.taylor_approx_two_segment

/-- One can get `f'' v w` as the limit of `h ^ (-2)` times the alternate sum of the values of `f`
along the vertices of a quadrilateral with sides `h v` and `h w` based at `x`.
In a setting where `f` is not guaranteed to be continuous at `f`, we can still
get this if we use a quadrilateral based at `h v + h w`. -/
theorem Convex.isLittleO_alternate_sum_square {v w : E} (h4v : x + (4 : â„) â€¢ v âˆˆ interior s)
    (h4w : x + (4 : â„) â€¢ w âˆˆ interior s) :
    (fun h : â„ => f (x + h â€¢ (2 â€¢ v + 2 â€¢ w)) + f (x + h â€¢ (v + w))
        - f (x + h â€¢ (2 â€¢ v + w)) - f (x + h â€¢ (v + 2 â€¢ w)) - h ^ 2 â€¢ f'' v w) =o[ğ“[>] 0]
      fun h => h ^ 2 := by
  have A : (1 : â„) / 2 âˆˆ Ioc (0 : â„) 1 := âŸ¨by norm_num, by norm_numâŸ©
  have B : (1 : â„) / 2 âˆˆ Icc (0 : â„) 1 := âŸ¨by norm_num, by norm_numâŸ©
  have C : âˆ€ w : E, (2 : â„) â€¢ w = 2 â€¢ w := fun w => by simp only [two_smul]
  have h2v2w : x + (2 : â„) â€¢ v + (2 : â„) â€¢ w âˆˆ interior s := by
    convert s_conv.interior.add_smul_sub_mem h4v h4w B using 1
    simp only [smul_sub, smul_smul, one_div, add_sub_add_left_eq_sub, mul_add, add_smul]
    norm_num
    simp only [show (4 : â„) = (2 : â„) + (2 : â„) by norm_num, _root_.add_smul]
    abel
  have h2vww : x + (2 â€¢ v + w) + w âˆˆ interior s := by
    convert h2v2w using 1
    simp only [two_smul]
    abel
  have h2v : x + (2 : â„) â€¢ v âˆˆ interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4v A using 1
    simp only [smul_smul, one_div, add_sub_cancel_left, add_right_inj]
    norm_num
  have h2w : x + (2 : â„) â€¢ w âˆˆ interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4w A using 1
    simp only [smul_smul, one_div, add_sub_cancel_left, add_right_inj]
    norm_num
  have hvw : x + (v + w) âˆˆ interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h2v2w A using 1
    simp only [smul_smul, one_div, add_sub_cancel_left, add_right_inj, smul_add, smul_sub]
    norm_num
    abel
  have h2vw : x + (2 â€¢ v + w) âˆˆ interior s := by
    convert s_conv.interior.add_smul_sub_mem h2v h2v2w B using 1
    simp only [smul_add, smul_sub, smul_smul, â† C]
    norm_num
    abel
  have hvww : x + (v + w) + w âˆˆ interior s := by
    convert s_conv.interior.add_smul_sub_mem h2w h2v2w B using 1
    rw [one_div, add_sub_add_right_eq_sub, add_sub_cancel_left, inv_smul_smulâ‚€ two_ne_zero,
      two_smul]
    abel
  have TA1 := s_conv.taylor_approx_two_segment hf xs hx h2vw h2vww
  have TA2 := s_conv.taylor_approx_two_segment hf xs hx hvw hvww
  convert TA1.sub TA2 using 1
  ext h
  simp only [two_smul, smul_add, â† add_assoc, ContinuousLinearMap.map_add,
    ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul',
    ContinuousLinearMap.map_smul]
  abel
#align convex.is_o_alternate_sum_square Convex.isLittleO_alternate_sum_square

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one
has `f'' v w = f'' w v`. Superseded by `Convex.second_derivative_within_at_symmetric`, which
removes the assumption that `v` and `w` point inside `s`. -/
theorem Convex.second_derivative_within_at_symmetric_of_mem_interior {v w : E}
    (h4v : x + (4 : â„) â€¢ v âˆˆ interior s) (h4w : x + (4 : â„) â€¢ w âˆˆ interior s) :
    f'' w v = f'' v w := by
  have A : (fun h : â„ => h ^ 2 â€¢ (f'' w v - f'' v w)) =o[ğ“[>] 0] fun h => h ^ 2 := by
    convert (s_conv.isLittleO_alternate_sum_square hf xs hx h4v h4w).sub
      (s_conv.isLittleO_alternate_sum_square hf xs hx h4w h4v) using 1
    ext h
    simp only [add_comm, smul_add, smul_sub]
    abel
  have B : (fun _ : â„ => f'' w v - f'' v w) =o[ğ“[>] 0] fun _ => (1 : â„) := by
    have : (fun h : â„ => 1 / h ^ 2) =O[ğ“[>] 0] fun h => 1 / h ^ 2 := isBigO_refl _ _
    have C := this.smul_isLittleO A
    apply C.congr' _ _
    Â· filter_upwards [self_mem_nhdsWithin]
      intro h (hpos : 0 < h)
      rw [â† one_smul â„ (f'' w v - f'' v w), smul_smul, smul_smul]
      congr 1
      field_simp [LT.lt.ne' hpos]
    Â· filter_upwards [self_mem_nhdsWithin] with h (hpos : 0 < h)
      field_simp [LT.lt.ne' hpos, SMul.smul]
  simpa only [sub_eq_zero] using isLittleO_const_const_iff.1 B
#align convex.second_derivative_within_at_symmetric_of_mem_interior Convex.second_derivative_within_at_symmetric_of_mem_interior

/-- If a function is differentiable inside a convex set with nonempty interior, and has a second
derivative at a point of this convex set, then this second derivative is symmetric. -/
theorem Convex.second_derivative_within_at_symmetric {s : Set E} (s_conv : Convex â„ s)
    (hne : (interior s).Nonempty) {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F}
    (hf : âˆ€ x âˆˆ interior s, HasFDerivAt f (f' x) x) {x : E} (xs : x âˆˆ s)
    (hx : HasFDerivWithinAt f' f'' (interior s) x) (v w : E) : f'' v w = f'' w v := by
  /- we work around a point `x + 4 z` in the interior of `s`. For any vector `m`,
    then `x + 4 (z + t m)` also belongs to the interior of `s` for small enough `t`. This means that
    we will be able to apply `second_derivative_within_at_symmetric_of_mem_interior` to show
    that `f''` is symmetric, after cancelling all the contributions due to `z`. -/
  rcases hne with âŸ¨y, hyâŸ©
  obtain âŸ¨z, hzâŸ© : âˆƒ z, z = ((1 : â„) / 4) â€¢ (y - x) := âŸ¨((1 : â„) / 4) â€¢ (y - x), rflâŸ©
  have A : âˆ€ m : E, Filter.Tendsto (fun t : â„ => x + (4 : â„) â€¢ (z + t â€¢ m)) (ğ“ 0) (ğ“ y) := by
    intro m
    have : x + (4 : â„) â€¢ (z + (0 : â„) â€¢ m) = y := by simp [hz]
    rw [â† this]
    refine tendsto_const_nhds.add <| tendsto_const_nhds.smul <| tendsto_const_nhds.add ?_
    exact continuousAt_id.smul continuousAt_const
  have B : âˆ€ m : E, âˆ€á¶  t in ğ“[>] (0 : â„), x + (4 : â„) â€¢ (z + t â€¢ m) âˆˆ interior s := by
    intro m
    apply nhdsWithin_le_nhds
    apply A m
    rw [mem_interior_iff_mem_nhds] at hy
    exact interior_mem_nhds.2 hy
  -- we choose `t m > 0` such that `x + 4 (z + (t m) m)` belongs to the interior of `s`, for any
  -- vector `m`.
  choose t ts tpos using fun m => ((B m).and self_mem_nhdsWithin).exists
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z`
  -- and `z + (t m) m`, we deduce that `f'' m z = f'' z m` for all `m`.
  have C : âˆ€ m : E, f'' m z = f'' z m := by
    intro m
    have : f'' (z + t m â€¢ m) (z + t 0 â€¢ (0 : E)) = f'' (z + t 0 â€¢ (0 : E)) (z + t m â€¢ m) :=
      s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts 0) (ts m)
    simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.map_smul, add_right_inj,
      ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul', add_zero,
      ContinuousLinearMap.zero_apply, smul_zero, ContinuousLinearMap.map_zero] at this
    exact smul_right_injective F (tpos m).ne' this
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z + (t v) v`
  -- and `z + (t w) w`, we deduce that `f'' v w = f'' w v`. Cross terms involving `z` can be
  -- eliminated thanks to the fact proved above that `f'' m z = f'' z m`.
  have : f'' (z + t v â€¢ v) (z + t w â€¢ w) = f'' (z + t w â€¢ w) (z + t v â€¢ v) :=
    s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts w) (ts v)
  simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.map_smul, smul_add, smul_smul,
    ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul', C] at this
  rw [add_assoc, add_assoc, add_right_inj, add_left_comm, add_right_inj, add_right_inj, mul_comm]
    at this
  apply smul_right_injective F _ this
  simp [(tpos v).ne', (tpos w).ne']
#align convex.second_derivative_within_at_symmetric Convex.second_derivative_within_at_symmetric

/-- If a function is differentiable around `x`, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric_of_eventually {f : E â†’ F} {f' : E â†’ E â†’L[â„] F}
    {f'' : E â†’L[â„] E â†’L[â„] F} (hf : âˆ€á¶  y in ğ“ x, HasFDerivAt f (f' y) y) (hx : HasFDerivAt f' f'' x)
    (v w : E) : f'' v w = f'' w v := by
  rcases Metric.mem_nhds_iff.1 hf with âŸ¨Îµ, Îµpos, hÎµâŸ©
  have A : (interior (Metric.ball x Îµ)).Nonempty := by
    rwa [Metric.isOpen_ball.interior_eq, Metric.nonempty_ball]
  exact
    Convex.second_derivative_within_at_symmetric (convex_ball x Îµ) A
      (fun y hy => hÎµ (interior_subset hy)) (Metric.mem_ball_self Îµpos) hx.hasFDerivWithinAt v w
#align second_derivative_symmetric_of_eventually second_derivative_symmetric_of_eventually

/-- If a function is differentiable, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F}
    (hf : âˆ€ y, HasFDerivAt f (f' y) y) (hx : HasFDerivAt f' f'' x) (v w : E) : f'' v w = f'' w v :=
  second_derivative_symmetric_of_eventually (Filter.eventually_of_forall hf) hx v w
#align second_derivative_symmetric second_derivative_symmetric
