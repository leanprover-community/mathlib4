/-
Copyright (c) 2021 SÃ©bastien GouÃ«zel. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: SÃ©bastien GouÃ«zel
-/
import Mathlib.Analysis.Analytic.IteratedFDeriv
import Mathlib.Analysis.Calculus.Deriv.Pow
import Mathlib.Analysis.Calculus.MeanValue
import Mathlib.Analysis.Calculus.ContDiff.Basic

/-!
# Symmetry of the second derivative

We show that, over the reals, the second derivative is symmetric.

The most precise result is `Convex.second_derivative_within_at_symmetric`. It asserts that,
if a function is differentiable inside a convex set `s` with nonempty interior, and has a second
derivative within `s` at a point `x`, then this second derivative at `x` is symmetric. Note that
this result does not require continuity of the first derivative.

The following particular cases of this statement are especially relevant:

`second_derivative_symmetric_of_eventually` asserts that, if a function is differentiable on a
neighborhood of `x`, and has a second derivative at `x`, then this second derivative is symmetric.

`second_derivative_symmetric` asserts that, if a function is differentiable, and has a second
derivative at `x`, then this second derivative is symmetric.

There statements are given over `â„` or `â„‚`, the general version being deduced from the real
version. We also give statements in terms of `fderiv` and `fderivWithin`, called respectively
`ContDiffAt.isSymmSndFDerivAt` and `ContDiffWithinAt.isSymmSndFDerivWithinAt` (the latter
requiring that the point under consideration is accumulated by points in the interior of the set).
These are written using ad hoc predicates `IsSymmSndFDerivAt` and `IsSymmSndFDerivWithinAt`, which
increase readability of statements in differential geometry where they show up a lot.

We also deduce statements over an arbitrary field, requiring that the function is `C^2` if the field
is `â„` or `â„‚`, and analytic otherwise. Formally, we assume that the function is `C^n`
with `minSmoothness ğ•œ 2 â‰¤ n`, where `minSmoothness ğ•œ i` is `i` if `ğ•œ` is `â„` or `â„‚`,
and `Ï‰` otherwise.

## Implementation note

For the proof, we obtain an asymptotic expansion to order two of `f (x + v + w) - f (x + v)`, by
using the mean value inequality applied to a suitable function along the
segment `[x + v, x + v + w]`. This expansion involves `f'' â¬ w` as we move along a segment directed
by `w` (see `Convex.taylor_approx_two_segment`).

Consider the alternate sum `f (x + v + w) + f x - f (x + v) - f (x + w)`, corresponding to the
values of `f` along a rectangle based at `x` with sides `v` and `w`. One can write it using the two
sides directed by `w`, as `(f (x + v + w) - f (x + v)) - (f (x + w) - f x)`. Together with the
previous asymptotic expansion, one deduces that it equals `f'' v w + o(1)` when `v, w` tends to `0`.
Exchanging the roles of `v` and `w`, one instead gets an asymptotic expansion `f'' w v`, from which
the equality `f'' v w = f'' w v` follows.

In our most general statement, we only assume that `f` is differentiable inside a convex set `s`, so
a few modifications have to be made. Since we don't assume continuity of `f` at `x`, we consider
instead the rectangle based at `x + v + w` with sides `v` and `w`,
in `Convex.isLittleO_alternate_sum_square`, but the argument is essentially the same. It only works
when `v` and `w` both point towards the interior of `s`, to make sure that all the sides of the
rectangle are contained in `s` by convexity. The general case follows by linearity, though.
-/


open Asymptotics Set Filter

open scoped Topology ContDiff

section General

variable {ğ•œ : Type*} [NontriviallyNormedField ğ•œ]
  {E F : Type*} [NormedAddCommGroup E] [NormedSpace ğ•œ E] [NormedAddCommGroup F]
  [NormedSpace ğ•œ F] {s t : Set E} {f : E â†’ F} {x : E}

variable (ğ•œ) in
/-- Definition recording that a function has a symmetric second derivative within a set at
a point. This is automatic in most cases of interest (open sets over real or complex vector fields,
or general case for analytic functions), but we can express theorems of calculus using this
as a general assumption, and then specialize to these situations. -/
def IsSymmSndFDerivWithinAt (f : E â†’ F) (s : Set E) (x : E) : Prop :=
  âˆ€ v w, fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x v w = fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x w v

variable (ğ•œ) in
/-- Definition recording that a function has a symmetric second derivative at
a point. This is automatic in most cases of interest (open sets over real or complex vector fields,
or general case for analytic functions), but we can express theorems of calculus using this
as a general assumption, and then specialize to these situations. -/
def IsSymmSndFDerivAt (f : E â†’ F) (x : E) : Prop :=
  âˆ€ v w, fderiv ğ•œ (fderiv ğ•œ f) x v w = fderiv ğ•œ (fderiv ğ•œ f) x w v

protected lemma IsSymmSndFDerivWithinAt.eq (h : IsSymmSndFDerivWithinAt ğ•œ f s x) (v w : E) :
    fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x v w = fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x w v :=
  h v w

protected lemma IsSymmSndFDerivAt.eq
    (h : IsSymmSndFDerivAt ğ•œ f x) (v w : E) :
    fderiv ğ•œ (fderiv ğ•œ f) x v w = fderiv ğ•œ (fderiv ğ•œ f) x w v :=
  h v w

lemma fderivWithin_fderivWithin_eq_of_mem_nhdsWithin (h : t âˆˆ ğ“[s] x)
    (hf : ContDiffWithinAt ğ•œ 2 f t x) (hs : UniqueDiffOn ğ•œ s) (ht : UniqueDiffOn ğ•œ t) (hx : x âˆˆ s) :
    fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x = fderivWithin ğ•œ (fderivWithin ğ•œ f t) t x := by
  have A : âˆ€á¶  y in ğ“[s] x, fderivWithin ğ•œ f s y = fderivWithin ğ•œ f t y := by
    have : âˆ€á¶  y in ğ“[s] x, ContDiffWithinAt ğ•œ 2 f t y :=
      nhdsWithin_le_iff.2 h (nhdsWithin_mono _ (subset_insert x t) (hf.eventually (by simp)))
    filter_upwards [self_mem_nhdsWithin, this, eventually_eventually_nhdsWithin.2 h]
      with y hy h'y h''y
    exact fderivWithin_of_mem_nhdsWithin h''y (hs y hy) (h'y.differentiableWithinAt one_le_two)
  have : fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x = fderivWithin ğ•œ (fderivWithin ğ•œ f t) s x := by
    apply Filter.EventuallyEq.fderivWithin_eq A
    exact fderivWithin_of_mem_nhdsWithin h (hs x hx) (hf.differentiableWithinAt one_le_two)
  rw [this]
  apply fderivWithin_of_mem_nhdsWithin h (hs x hx)
  exact (hf.fderivWithin_right (m := 1) ht le_rfl
    (mem_of_mem_nhdsWithin hx h)).differentiableWithinAt le_rfl

lemma fderivWithin_fderivWithin_eq_of_eventuallyEq (h : s =á¶ [ğ“ x] t) :
    fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x = fderivWithin ğ•œ (fderivWithin ğ•œ f t) t x := calc
  fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x
    = fderivWithin ğ•œ (fderivWithin ğ•œ f t) s x :=
      (fderivWithin_eventually_congr_set h).fderivWithin_eq_of_nhds
  _ = fderivWithin ğ•œ (fderivWithin ğ•œ f t) t x := fderivWithin_congr_set h

lemma fderivWithin_fderivWithin_eq_of_mem_nhds {f : E â†’ F} {x : E} {s : Set E}
    (h : s âˆˆ ğ“ x) :
    fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x = fderiv ğ•œ (fderiv ğ•œ f) x := by
  simp only [â† fderivWithin_univ]
  apply fderivWithin_fderivWithin_eq_of_eventuallyEq
  simp [h]

@[simp] lemma isSymmSndFDerivWithinAt_univ :
    IsSymmSndFDerivWithinAt ğ•œ f univ x â†” IsSymmSndFDerivAt ğ•œ f x := by
  simp [IsSymmSndFDerivWithinAt, IsSymmSndFDerivAt]

theorem IsSymmSndFDerivWithinAt.mono_of_mem_nhdsWithin (h : IsSymmSndFDerivWithinAt ğ•œ f t x)
    (hst : t âˆˆ ğ“[s] x) (hf : ContDiffWithinAt ğ•œ 2 f t x)
    (hs : UniqueDiffOn ğ•œ s) (ht : UniqueDiffOn ğ•œ t) (hx : x âˆˆ s) :
    IsSymmSndFDerivWithinAt ğ•œ f s x := by
  intro v w
  rw [fderivWithin_fderivWithin_eq_of_mem_nhdsWithin hst hf hs ht hx]
  exact h v w

theorem IsSymmSndFDerivWithinAt.congr_set (h : IsSymmSndFDerivWithinAt ğ•œ f s x)
    (hst : s =á¶ [ğ“ x] t) : IsSymmSndFDerivWithinAt ğ•œ f t x := by
  intro v w
  rw [fderivWithin_fderivWithin_eq_of_eventuallyEq hst.symm]
  exact h v w

theorem isSymmSndFDerivWithinAt_congr_set (hst : s =á¶ [ğ“ x] t) :
    IsSymmSndFDerivWithinAt ğ•œ f s x â†” IsSymmSndFDerivWithinAt ğ•œ f t x :=
  âŸ¨fun h â†¦ h.congr_set hst, fun h â†¦ h.congr_set hst.symmâŸ©

theorem IsSymmSndFDerivAt.isSymmSndFDerivWithinAt (h : IsSymmSndFDerivAt ğ•œ f x)
    (hf : ContDiffAt ğ•œ 2 f x) (hs : UniqueDiffOn ğ•œ s) (hx : x âˆˆ s) :
    IsSymmSndFDerivWithinAt ğ•œ f s x := by
  simp only [â† isSymmSndFDerivWithinAt_univ, â† contDiffWithinAt_univ] at h hf
  exact h.mono_of_mem_nhdsWithin univ_mem hf hs uniqueDiffOn_univ hx

theorem isSymmSndFDerivWithinAt_iff_iteratedFDerivWithin (hs : UniqueDiffOn ğ•œ s) (hx : x âˆˆ s) :
    IsSymmSndFDerivWithinAt ğ•œ f s x â†”
      (iteratedFDerivWithin ğ•œ 2 f s x).domDomCongr Fin.revPerm =
        iteratedFDerivWithin ğ•œ 2 f s x := by
  simp_rw [IsSymmSndFDerivWithinAt, ContinuousMultilinearMap.ext_iff, Fin.forall_fin_succ_pi,
    Fin.forall_fin_zero_pi]
  simp [iteratedFDerivWithin_two_apply f hs hx, eq_comm]

theorem isSymmSndFDerivAt_iff_iteratedFDeriv :
    IsSymmSndFDerivAt ğ•œ f x â†”
      (iteratedFDeriv ğ•œ 2 f x).domDomCongr Fin.revPerm = iteratedFDeriv ğ•œ 2 f x := by
  simp only [â† isSymmSndFDerivWithinAt_univ, â† iteratedFDerivWithin_univ]
  exact isSymmSndFDerivWithinAt_iff_iteratedFDerivWithin uniqueDiffOn_univ (mem_univ _)

theorem IsSymmSndFDerivWithinAt.iteratedFDerivWithin_cons {x v w : E}
    {hf : IsSymmSndFDerivWithinAt ğ•œ f s x} (hs : UniqueDiffOn ğ•œ s) (hx : x âˆˆ s) :
    iteratedFDerivWithin ğ•œ 2 f s x ![v, w] = iteratedFDerivWithin ğ•œ 2 f s x ![w, v] := by
  simp_rw [isSymmSndFDerivWithinAt_iff_iteratedFDerivWithin hs hx, ContinuousMultilinearMap.ext_iff,
    ContinuousMultilinearMap.domDomCongr_apply] at hf
  convert hf ![w, v] using 2
  ext i
  fin_cases i <;> simp

theorem IsSymmSndFDerivAt.iteratedFDeriv_cons {x v w : E} {hf : IsSymmSndFDerivAt ğ•œ f x} :
    iteratedFDeriv ğ•œ 2 f x ![v, w] = iteratedFDeriv ğ•œ 2 f x ![w, v] := by
  simp only [â† isSymmSndFDerivWithinAt_univ, â† iteratedFDerivWithin_univ] at *
  exact hf.iteratedFDerivWithin_cons uniqueDiffOn_univ (mem_univ _)

/-- If a function is analytic within a set at a point, then its second derivative is symmetric. -/
theorem ContDiffWithinAt.isSymmSndFDerivWithinAt_of_omega (hf : ContDiffWithinAt ğ•œ Ï‰ f s x)
    (hs : UniqueDiffOn ğ•œ s) (hx : x âˆˆ s) :
    IsSymmSndFDerivWithinAt ğ•œ f s x := by
  rw [isSymmSndFDerivWithinAt_iff_iteratedFDerivWithin hs hx]
  exact hf.domDomCongr_iteratedFDerivWithin hs hx _

/-- If a function is analytic at a point, then its second derivative is symmetric. -/
theorem ContDiffAt.isSymmSndFDerivAt_of_omega (hf : ContDiffAt ğ•œ Ï‰ f x) :
    IsSymmSndFDerivAt ğ•œ f x := by
  simp only [â† isSymmSndFDerivWithinAt_univ, â† contDiffWithinAt_univ] at hf âŠ¢
  exact hf.isSymmSndFDerivWithinAt_of_omega uniqueDiffOn_univ (mem_univ _)

end General

section Real

variable {E F : Type*} [NormedAddCommGroup E] [NormedSpace â„ E] [NormedAddCommGroup F]
  [NormedSpace â„ F] {s : Set E} (s_conv : Convex â„ s) {f : E â†’ F} {f' : E â†’ E â†’L[â„] F}
  {f'' : E â†’L[â„] E â†’L[â„] F} (hf : âˆ€ x âˆˆ interior s, HasFDerivAt f (f' x) x) {x : E} (xs : x âˆˆ s)
  (hx : HasFDerivWithinAt f' f'' (interior s) x)

section
include s_conv hf xs hx

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one can
Taylor-expand to order two the function `f` on the segment `[x + h v, x + h (v + w)]`, giving a
bilinear estimate for `f (x + hv + hw) - f (x + hv)` in terms of `f' w` and of `f'' â¬ w`, up to
`o(h^2)`.

This is a technical statement used to show that the second derivative is symmetric. -/
theorem Convex.taylor_approx_two_segment {v w : E} (hv : x + v âˆˆ interior s)
    (hw : x + v + w âˆˆ interior s) :
    (fun h : â„ => f (x + h â€¢ v + h â€¢ w)
        - f (x + h â€¢ v) - h â€¢ f' x w - h ^ 2 â€¢ f'' v w - (h ^ 2 / 2) â€¢ f'' w w) =o[ğ“[>] 0]
      fun h => h ^ 2 := by
  -- it suffices to check that the expression is bounded by `Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h^2` for
  -- small enough `h`, for any positive `Îµ`.
  refine IsLittleO.trans_isBigO
    (isLittleO_iff.2 fun Îµ Îµpos => ?_) (isBigO_const_mul_self ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) _ _)
  -- consider a ball of radius `Î´` around `x` in which the Taylor approximation for `f''` is
  -- good up to `Î´`.
  rw [HasFDerivWithinAt, hasFDerivAtFilter_iff_isLittleO, isLittleO_iff] at hx
  rcases Metric.mem_nhdsWithin_iff.1 (hx Îµpos) with âŸ¨Î´, Î´pos, sÎ´âŸ©
  have E1 : âˆ€á¶  h in ğ“[>] (0 : â„), h * (â€–vâ€– + â€–wâ€–) < Î´ := by
    have : Filter.Tendsto (fun h => h * (â€–vâ€– + â€–wâ€–)) (ğ“[>] (0 : â„)) (ğ“ (0 * (â€–vâ€– + â€–wâ€–))) :=
      (continuous_id.mul continuous_const).continuousWithinAt
    apply (tendsto_order.1 this).2 Î´
    simpa only [zero_mul] using Î´pos
  have E2 : âˆ€á¶  h in ğ“[>] (0 : â„), (h : â„) < 1 :=
    mem_nhdsWithin_of_mem_nhds <| Iio_mem_nhds zero_lt_one
  filter_upwards [E1, E2, self_mem_nhdsWithin] with h hÎ´ h_lt_1 hpos
  -- we consider `h` small enough that all points under consideration belong to this ball,
  -- and also with `0 < h < 1`.
  replace hpos : 0 < h := hpos
  have xt_mem : âˆ€ t âˆˆ Icc (0 : â„) 1, x + h â€¢ v + (t * h) â€¢ w âˆˆ interior s := by
    intro t ht
    have : x + h â€¢ v âˆˆ interior s := s_conv.add_smul_mem_interior xs hv âŸ¨hpos, h_lt_1.leâŸ©
    rw [â† smul_smul]
    apply s_conv.interior.add_smul_mem this _ ht
    rw [add_assoc] at hw
    convert s_conv.add_smul_mem_interior xs hw âŸ¨hpos, h_lt_1.leâŸ© using 1
    module
  -- define a function `g` on `[0,1]` (identified with `[v, v + w]`) such that `g 1 - g 0` is the
  -- quantity to be estimated. We will check that its derivative is given by an explicit
  -- expression `g'`, that we can bound. Then the desired bound for `g 1 - g 0` follows from the
  -- mean value inequality.
  let g t :=
    f (x + h â€¢ v + (t * h) â€¢ w) - (t * h) â€¢ f' x w - (t * h ^ 2) â€¢ f'' v w -
      ((t * h) ^ 2 / 2) â€¢ f'' w w
  set g' := fun t =>
    f' (x + h â€¢ v + (t * h) â€¢ w) (h â€¢ w) - h â€¢ f' x w - h ^ 2 â€¢ f'' v w - (t * h ^ 2) â€¢ f'' w w
    with hg'
  -- check that `g'` is the derivative of `g`, by a straightforward computation
  have g_deriv : âˆ€ t âˆˆ Icc (0 : â„) 1, HasDerivWithinAt g (g' t) (Icc 0 1) t := by
    intro t ht
    apply_rules [HasDerivWithinAt.sub, HasDerivWithinAt.add]
    Â· refine (hf _ ?_).comp_hasDerivWithinAt _ ?_
      Â· exact xt_mem t ht
      apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.const_add, HasDerivAt.smul_const,
        hasDerivAt_mul_const]
    Â· apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_mul_const]
    Â· apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_mul_const]
    Â· suffices H : HasDerivWithinAt (fun u => ((u * h) ^ 2 / 2) â€¢ f'' w w)
          ((((2 : â„•) : â„) * (t * h) ^ (2 - 1) * (1 * h) / 2) â€¢ f'' w w) (Icc 0 1) t by
        convert H using 2
        ring
      apply_rules [HasDerivAt.hasDerivWithinAt, HasDerivAt.smul_const, hasDerivAt_id',
        HasDerivAt.pow, HasDerivAt.mul_const]
  -- check that `g'` is uniformly bounded, with a suitable bound `Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h^2`.
  have g'_bound : âˆ€ t âˆˆ Ico (0 : â„) 1, â€–g' tâ€– â‰¤ Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h ^ 2 := by
    intro t ht
    have I : â€–h â€¢ v + (t * h) â€¢ wâ€– â‰¤ h * (â€–vâ€– + â€–wâ€–) :=
      calc
        â€–h â€¢ v + (t * h) â€¢ wâ€– â‰¤ â€–h â€¢ vâ€– + â€–(t * h) â€¢ wâ€– := norm_add_le _ _
        _ = h * â€–vâ€– + t * (h * â€–wâ€–) := by
          simp only [norm_smul, Real.norm_eq_abs, hpos.le, abs_of_nonneg, abs_mul, ht.left,
            mul_assoc]
        _ â‰¤ h * â€–vâ€– + 1 * (h * â€–wâ€–) := by gcongr; exact ht.2.le
        _ = h * (â€–vâ€– + â€–wâ€–) := by ring
    calc
      â€–g' tâ€– = â€–(f' (x + h â€¢ v + (t * h) â€¢ w) - f' x - f'' (h â€¢ v + (t * h) â€¢ w)) (h â€¢ w)â€– := by
        rw [hg']
        congrm â€–?_â€–
        simp only [ContinuousLinearMap.sub_apply, ContinuousLinearMap.add_apply,
          ContinuousLinearMap.smul_apply, map_add, map_smul]
        module
      _ â‰¤ â€–f' (x + h â€¢ v + (t * h) â€¢ w) - f' x - f'' (h â€¢ v + (t * h) â€¢ w)â€– * â€–h â€¢ wâ€– :=
        (ContinuousLinearMap.le_opNorm _ _)
      _ â‰¤ Îµ * â€–h â€¢ v + (t * h) â€¢ wâ€– * â€–h â€¢ wâ€– := by
        gcongr
        have H : x + h â€¢ v + (t * h) â€¢ w âˆˆ Metric.ball x Î´ âˆ© interior s := by
          refine âŸ¨?_, xt_mem t âŸ¨ht.1, ht.2.leâŸ©âŸ©
          rw [add_assoc, add_mem_ball_iff_norm]
          exact I.trans_lt hÎ´
        simpa only [mem_setOf_eq, add_assoc x, add_sub_cancel_left] using sÎ´ H
      _ â‰¤ Îµ * (â€–h â€¢ vâ€– + â€–h â€¢ wâ€–) * â€–h â€¢ wâ€– := by
        gcongr
        apply (norm_add_le _ _).trans
        gcongr
        simp only [norm_smul, Real.norm_eq_abs, abs_mul, abs_of_nonneg, ht.1, hpos.le, mul_assoc]
        exact mul_le_of_le_one_left (by positivity) ht.2.le
      _ = Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h ^ 2 := by
        simp only [norm_smul, Real.norm_eq_abs, abs_of_nonneg, hpos.le]; ring
  -- conclude using the mean value inequality
  have I : â€–g 1 - g 0â€– â‰¤ Îµ * ((â€–vâ€– + â€–wâ€–) * â€–wâ€–) * h ^ 2 := by
    simpa only [mul_one, sub_zero] using
      norm_image_sub_le_of_norm_deriv_le_segment' g_deriv g'_bound 1 (right_mem_Icc.2 zero_le_one)
  convert I using 1
  Â· congr 1
    simp only [g, add_zero, one_mul, zero_div, zero_mul, sub_zero,
      zero_smul, Ne, not_false_iff, zero_pow, reduceCtorEq]
    abel
  Â· simp (discharger := positivity) only [Real.norm_eq_abs, abs_of_nonneg]
    ring

/-- One can get `f'' v w` as the limit of `h ^ (-2)` times the alternate sum of the values of `f`
along the vertices of a quadrilateral with sides `h v` and `h w` based at `x`.
In a setting where `f` is not guaranteed to be continuous at `f`, we can still
get this if we use a quadrilateral based at `h v + h w`. -/
theorem Convex.isLittleO_alternate_sum_square {v w : E} (h4v : x + (4 : â„) â€¢ v âˆˆ interior s)
    (h4w : x + (4 : â„) â€¢ w âˆˆ interior s) :
    (fun h : â„ => f (x + h â€¢ (2 â€¢ v + 2 â€¢ w)) + f (x + h â€¢ (v + w))
        - f (x + h â€¢ (2 â€¢ v + w)) - f (x + h â€¢ (v + 2 â€¢ w)) - h ^ 2 â€¢ f'' v w) =o[ğ“[>] 0]
      fun h => h ^ 2 := by
  have A : (1 : â„) / 2 âˆˆ Ioc (0 : â„) 1 := âŸ¨by simp, by norm_numâŸ©
  have B : (1 : â„) / 2 âˆˆ Icc (0 : â„) 1 := âŸ¨by simp, by norm_numâŸ©
  have h2v2w : x + (2 : â„) â€¢ v + (2 : â„) â€¢ w âˆˆ interior s := by
    convert s_conv.interior.add_smul_sub_mem h4v h4w B using 1
    module
  have h2vww : x + (2 â€¢ v + w) + w âˆˆ interior s := by
    convert h2v2w using 1
    module
  have h2v : x + (2 : â„) â€¢ v âˆˆ interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4v A using 1
    module
  have h2w : x + (2 : â„) â€¢ w âˆˆ interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h4w A using 1
    module
  have hvw : x + (v + w) âˆˆ interior s := by
    convert s_conv.add_smul_sub_mem_interior xs h2v2w A using 1
    module
  have h2vw : x + (2 â€¢ v + w) âˆˆ interior s := by
    convert s_conv.interior.add_smul_sub_mem h2v h2v2w B using 1
    module
  have hvww : x + (v + w) + w âˆˆ interior s := by
    convert s_conv.interior.add_smul_sub_mem h2w h2v2w B using 1
    module
  have TA1 := s_conv.taylor_approx_two_segment hf xs hx h2vw h2vww
  have TA2 := s_conv.taylor_approx_two_segment hf xs hx hvw hvww
  convert TA1.sub TA2 using 1
  ext h
  simp only [two_smul, smul_add, â† add_assoc, ContinuousLinearMap.map_add,
    ContinuousLinearMap.add_apply]
  abel

/-- Assume that `f` is differentiable inside a convex set `s`, and that its derivative `f'` is
differentiable at a point `x`. Then, given two vectors `v` and `w` pointing inside `s`, one
has `f'' v w = f'' w v`. Superseded by `Convex.second_derivative_within_at_symmetric`, which
removes the assumption that `v` and `w` point inside `s`. -/
theorem Convex.second_derivative_within_at_symmetric_of_mem_interior {v w : E}
    (h4v : x + (4 : â„) â€¢ v âˆˆ interior s) (h4w : x + (4 : â„) â€¢ w âˆˆ interior s) :
    f'' w v = f'' v w := by
  have A : (fun h : â„ => h ^ 2 â€¢ (f'' w v - f'' v w)) =o[ğ“[>] 0] fun h => h ^ 2 := by
    convert (s_conv.isLittleO_alternate_sum_square hf xs hx h4v h4w).sub
      (s_conv.isLittleO_alternate_sum_square hf xs hx h4w h4v) using 1
    ext h
    simp only [add_comm, smul_add, smul_sub]
    abel
  have B : (fun _ : â„ => f'' w v - f'' v w) =o[ğ“[>] 0] fun _ => (1 : â„) := by
    have : (fun h : â„ => 1 / h ^ 2) =O[ğ“[>] 0] fun h => 1 / h ^ 2 := isBigO_refl _ _
    have C := this.smul_isLittleO A
    apply C.congr' _ _
    Â· filter_upwards [self_mem_nhdsWithin]
      intro h (hpos : 0 < h)
      match_scalars <;> field_simp
    Â· filter_upwards [self_mem_nhdsWithin] with h (hpos : 0 < h)
      simp [field]
  simpa only [sub_eq_zero] using isLittleO_const_const_iff.1 B

end

/-- If a function is differentiable inside a convex set with nonempty interior, and has a second
derivative at a point of this convex set, then this second derivative is symmetric. -/
theorem Convex.second_derivative_within_at_symmetric {s : Set E} (s_conv : Convex â„ s)
    (hne : (interior s).Nonempty) {f : E â†’ F} {f' : E â†’ E â†’L[â„] F} {f'' : E â†’L[â„] E â†’L[â„] F}
    (hf : âˆ€ x âˆˆ interior s, HasFDerivAt f (f' x) x) {x : E} (xs : x âˆˆ s)
    (hx : HasFDerivWithinAt f' f'' (interior s) x) (v w : E) : f'' v w = f'' w v := by
  /- we work around a point `x + 4 z` in the interior of `s`. For any vector `m`,
    then `x + 4 (z + t m)` also belongs to the interior of `s` for small enough `t`. This means that
    we will be able to apply `second_derivative_within_at_symmetric_of_mem_interior` to show
    that `f''` is symmetric, after cancelling all the contributions due to `z`. -/
  rcases hne with âŸ¨y, hyâŸ©
  obtain âŸ¨z, hzâŸ© : âˆƒ z, z = ((1 : â„) / 4) â€¢ (y - x) := âŸ¨((1 : â„) / 4) â€¢ (y - x), rflâŸ©
  have A : âˆ€ m : E, Filter.Tendsto (fun t : â„ => x + (4 : â„) â€¢ (z + t â€¢ m)) (ğ“ 0) (ğ“ y) := by
    intro m
    have : x + (4 : â„) â€¢ (z + (0 : â„) â€¢ m) = y := by simp [hz]
    rw [â† this]
    refine tendsto_const_nhds.add <| tendsto_const_nhds.smul <| tendsto_const_nhds.add ?_
    exact continuousAt_id.smul continuousAt_const
  have B : âˆ€ m : E, âˆ€á¶  t in ğ“[>] (0 : â„), x + (4 : â„) â€¢ (z + t â€¢ m) âˆˆ interior s := by
    intro m
    apply nhdsWithin_le_nhds
    apply A m
    rw [mem_interior_iff_mem_nhds] at hy
    exact interior_mem_nhds.2 hy
  -- we choose `t m > 0` such that `x + 4 (z + (t m) m)` belongs to the interior of `s`, for any
  -- vector `m`.
  choose t ts tpos using fun m => ((B m).and self_mem_nhdsWithin).exists
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z`
  -- and `z + (t m) m`, we deduce that `f'' m z = f'' z m` for all `m`.
  have C : âˆ€ m : E, f'' m z = f'' z m := by
    intro m
    have : f'' (z + t m â€¢ m) (z + t 0 â€¢ (0 : E)) = f'' (z + t 0 â€¢ (0 : E)) (z + t m â€¢ m) :=
      s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts 0) (ts m)
    simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.map_smul, add_right_inj,
      ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul', add_zero,
      smul_zero] at this
    exact smul_right_injective F (tpos m).ne' this
  -- applying `second_derivative_within_at_symmetric_of_mem_interior` to the vectors `z + (t v) v`
  -- and `z + (t w) w`, we deduce that `f'' v w = f'' w v`. Cross terms involving `z` can be
  -- eliminated thanks to the fact proved above that `f'' m z = f'' z m`.
  have : f'' (z + t v â€¢ v) (z + t w â€¢ w) = f'' (z + t w â€¢ w) (z + t v â€¢ v) :=
    s_conv.second_derivative_within_at_symmetric_of_mem_interior hf xs hx (ts w) (ts v)
  simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.map_smul, smul_smul,
    ContinuousLinearMap.add_apply, Pi.smul_apply, ContinuousLinearMap.coe_smul', C] at this
  have : (t v * t w) â€¢ (f'' v) w = (t v * t w) â€¢ (f'' w) v := by
    linear_combination (norm := module) this
  apply smul_right_injective F _ this
  simp [(tpos v).ne', (tpos w).ne']

/-- If a function is differentiable around `x`, and has two derivatives at `x`, then the second
derivative is symmetric. Version over `â„`. See `second_derivative_symmetric_of_eventually` for a
version over `â„` or `â„‚`. -/
theorem second_derivative_symmetric_of_eventually_of_real {f : E â†’ F} {f' : E â†’ E â†’L[â„] F}
    {f'' : E â†’L[â„] E â†’L[â„] F} (hf : âˆ€á¶  y in ğ“ x, HasFDerivAt f (f' y) y) (hx : HasFDerivAt f' f'' x)
    (v w : E) : f'' v w = f'' w v := by
  rcases Metric.mem_nhds_iff.1 hf with âŸ¨Îµ, Îµpos, hÎµâŸ©
  have A : (interior (Metric.ball x Îµ)).Nonempty := by
    rwa [Metric.isOpen_ball.interior_eq, Metric.nonempty_ball]
  exact
    Convex.second_derivative_within_at_symmetric (convex_ball x Îµ) A
      (fun y hy => hÎµ (interior_subset hy)) (Metric.mem_ball_self Îµpos) hx.hasFDerivWithinAt v w

end Real

section IsRCLikeNormedField

variable {ğ•œ : Type*} [NontriviallyNormedField ğ•œ]
  {E F : Type*} [NormedAddCommGroup E] [NormedSpace ğ•œ E] [NormedAddCommGroup F]
  [NormedSpace ğ•œ F] {s : Set E} {f : E â†’ F} {x : E}

theorem second_derivative_symmetric_of_eventually [IsRCLikeNormedField ğ•œ]
    {f' : E â†’ E â†’L[ğ•œ] F} {x : E}
    {f'' : E â†’L[ğ•œ] E â†’L[ğ•œ] F} (hf : âˆ€á¶  y in ğ“ x, HasFDerivAt f (f' y) y)
    (hx : HasFDerivAt f' f'' x) (v w : E) : f'' v w = f'' w v := by
  let _ := IsRCLikeNormedField.rclike ğ•œ
  let _ : NormedSpace â„ E := NormedSpace.restrictScalars â„ ğ•œ E
  let _ : NormedSpace â„ F := NormedSpace.restrictScalars â„ ğ•œ F
  let _ : LinearMap.CompatibleSMul E F â„ ğ•œ := LinearMap.IsScalarTower.compatibleSMul
  let _ : LinearMap.CompatibleSMul E (E â†’L[ğ•œ] F) â„ ğ•œ := LinearMap.IsScalarTower.compatibleSMul
  let f'R : E â†’ E â†’L[â„] F := fun x â†¦ (f' x).restrictScalars â„
  have hfR : âˆ€á¶  y in ğ“ x, HasFDerivAt f (f'R y) y := by
    filter_upwards [hf] with y hy using HasFDerivAt.restrictScalars â„ hy
  let f''Rl : E â†’â‚—[â„] E â†’â‚—[â„] F :=
  { toFun := fun x â†¦
      { toFun := fun y â†¦ f'' x y
        map_add' := by simp
        map_smul' := by simp }
    map_add' := by intros; ext; simp
    map_smul' := by intros; ext; simp }
  let f''R : E â†’L[â„] E â†’L[â„] F := by
    refine LinearMap.mkContinuousâ‚‚ f''Rl (â€–f''â€–) (fun x y â†¦ ?_)
    simp only [LinearMap.coe_mk, AddHom.coe_mk, f''Rl]
    exact ContinuousLinearMap.le_opNormâ‚‚ f'' x y
  have : HasFDerivAt f'R f''R x := by
    simp only [hasFDerivAt_iff_tendsto] at hx âŠ¢
    exact hx
  change f''R v w = f''R w v
  exact second_derivative_symmetric_of_eventually_of_real hfR this v w

/-- If a function is differentiable, and has two derivatives at `x`, then the second
derivative is symmetric. -/
theorem second_derivative_symmetric [IsRCLikeNormedField ğ•œ]
    {f' : E â†’ E â†’L[ğ•œ] F} {f'' : E â†’L[ğ•œ] E â†’L[ğ•œ] F} {x : E}
    (hf : âˆ€ y, HasFDerivAt f (f' y) y) (hx : HasFDerivAt f' f'' x) (v w : E) : f'' v w = f'' w v :=
  second_derivative_symmetric_of_eventually (Filter.Eventually.of_forall hf) hx v w

open scoped Classical in
variable (ğ•œ) in
/-- `minSmoothness ğ•œ n` is the minimal smoothness exponent larger than or equal to `n` for which
one can do serious calculus in `ğ•œ`. If `ğ•œ` is `â„` or `â„‚`, this is just `n`. Otherwise,
this is `Ï‰` as only analytic functions are well behaved on `â„šâ‚š`, say. -/
noncomputable irreducible_def minSmoothness (n : WithTop â„•âˆ) :=
  if IsRCLikeNormedField ğ•œ then n else Ï‰

@[simp] lemma minSmoothness_of_isRCLikeNormedField [h : IsRCLikeNormedField ğ•œ] {n : WithTop â„•âˆ} :
    minSmoothness ğ•œ n = n := by
  simp [minSmoothness, h]

lemma le_minSmoothness {n : WithTop â„•âˆ} : n â‰¤ minSmoothness ğ•œ n := by
  simp only [minSmoothness]
  split_ifs <;> simp

lemma minSmoothness_add {n m : WithTop â„•âˆ} : minSmoothness ğ•œ (n + m) = minSmoothness ğ•œ n + m := by
  simp only [minSmoothness]
  split_ifs <;> simp

lemma minSmoothness_monotone : Monotone (minSmoothness ğ•œ) := by
  intro m n hmn
  simp only [minSmoothness]
  split_ifs <;> simp [hmn]

@[simp] lemma minSmoothness_eq_infty {n : WithTop â„•âˆ} :
    minSmoothness ğ•œ n = âˆ â†” (n = âˆ âˆ§ IsRCLikeNormedField ğ•œ) := by
  simp only [minSmoothness]
  split_ifs with h <;> simp [h]

/-- If `minSmoothness ğ•œ m â‰¤ n` for some (finite) integer `m`, then one can
find `n' âˆˆ [minSmoothness ğ•œ m, n]` which is not `âˆ`: over `â„` or `â„‚`, just take `m`, and otherwise
just take `Ï‰`. The interest of this technical lemma is that, if a function is `C^{n'}` at a point
for `n' â‰  âˆ`, then it is `C^{n'}` on a neighborhood of the point (this property fails only
in `C^âˆ` smoothness, see `ContDiffWithinAt.contDiffOn`). -/
lemma exist_minSmoothness_le_ne_infty {n : WithTop â„•âˆ} {m : â„•} (hm : minSmoothness ğ•œ m â‰¤ n) :
    âˆƒ n', minSmoothness ğ•œ m â‰¤ n' âˆ§ n' â‰¤ n âˆ§ n' â‰  âˆ := by
  simp only [minSmoothness] at hm âŠ¢
  split_ifs with h
  Â· simp only [h, â†“reduceIte] at hm
    exact âŸ¨m, le_rfl, hm, by simpâŸ©
  Â· simp only [h, â†“reduceIte, top_le_iff] at hm
    refine âŸ¨Ï‰, le_rfl, by simp [hm], by simpâŸ©

/-- If a function is `C^2` at a point, then its second derivative there is symmetric. Over a field
different from `â„` or `â„‚`, we should require that the function is analytic. -/
theorem ContDiffAt.isSymmSndFDerivAt {n : WithTop â„•âˆ}
    (hf : ContDiffAt ğ•œ n f x) (hn : minSmoothness ğ•œ 2 â‰¤ n) : IsSymmSndFDerivAt ğ•œ f x := by
  by_cases h : IsRCLikeNormedField ğ•œ
  -- First deal with the `â„` or `â„‚` case, where `C^2` is enough.
  Â· intro v w
    apply second_derivative_symmetric_of_eventually (f := f) (f' := fderiv ğ•œ f) (x := x)
    Â· obtain âŸ¨u, hu, h'uâŸ© : âˆƒ u âˆˆ ğ“ x, ContDiffOn ğ•œ 2 f u :=
        (hf.of_le hn).contDiffOn (m := 2) le_minSmoothness (by simp)
      rcases mem_nhds_iff.1 hu with âŸ¨v, vu, v_open, xvâŸ©
      filter_upwards [v_open.mem_nhds xv] with y hy
      have : DifferentiableAt ğ•œ f y := by
        have := (h'u.mono vu y hy).contDiffAt (v_open.mem_nhds hy)
        exact this.differentiableAt one_le_two
      exact DifferentiableAt.hasFDerivAt this
    Â· have : DifferentiableAt ğ•œ (fderiv ğ•œ f) x := by
        apply ContDiffAt.differentiableAt _ le_rfl
        exact hf.fderiv_right (le_minSmoothness.trans hn)
      exact DifferentiableAt.hasFDerivAt this
  -- then deal with the case of an arbitrary field, with analytic functions.
  Â· simp only [minSmoothness, h, â†“reduceIte, top_le_iff] at hn
    apply ContDiffAt.isSymmSndFDerivAt_of_omega
    simpa [hn] using hf

/-- If a function is `C^2` within a set at a point, and accumulated by points in the interior
of the set, then its second derivative there is symmetric. Over a field
different from `â„` or `â„‚`, we should require that the function is analytic. -/
theorem ContDiffWithinAt.isSymmSndFDerivWithinAt {n : WithTop â„•âˆ}
    (hf : ContDiffWithinAt ğ•œ n f s x) (hn : minSmoothness ğ•œ 2 â‰¤ n)
    (hs : UniqueDiffOn ğ•œ s) (hx : x âˆˆ closure (interior s)) (h'x : x âˆˆ s) :
    IsSymmSndFDerivWithinAt ğ•œ f s x := by
  /- We argue that, at interior points, the second derivative is symmetric, and moreover by
  continuity it converges to the second derivative at `x`. Therefore, the latter is also
  symmetric. -/
  obtain âŸ¨m, hm, hmn, m_neâŸ© := exist_minSmoothness_le_ne_infty hn
  rcases (hf.of_le hmn).contDiffOn' le_rfl (by simp [m_ne]) with âŸ¨u, u_open, xu, huâŸ©
  simp only [insert_eq_of_mem h'x] at hu
  have h'u : UniqueDiffOn ğ•œ (s âˆ© u) := hs.inter u_open
  obtain âŸ¨y, hy, y_limâŸ© : âˆƒ y, (âˆ€ (n : â„•), y n âˆˆ interior s) âˆ§ Tendsto y atTop (ğ“ x) :=
    mem_closure_iff_seq_limit.1 hx
  have L : âˆ€á¶  k in atTop, y k âˆˆ u := y_lim (u_open.mem_nhds xu)
  have I : âˆ€á¶  k in atTop, IsSymmSndFDerivWithinAt ğ•œ f s (y k) := by
    filter_upwards [L] with k hk
    have s_mem : s âˆˆ ğ“ (y k) := by
      apply mem_of_superset (isOpen_interior.mem_nhds (hy k))
      exact interior_subset
    have : IsSymmSndFDerivAt ğ•œ f (y k) := by
      apply ContDiffAt.isSymmSndFDerivAt _ (n := m) hm
      apply (hu (y k) âŸ¨(interior_subset (hy k)), hkâŸ©).contDiffAt
      exact inter_mem s_mem (u_open.mem_nhds hk)
    intro v w
    rw [fderivWithin_fderivWithin_eq_of_mem_nhds s_mem]
    exact this v w
  have A : ContinuousOn (fderivWithin ğ•œ (fderivWithin ğ•œ f s) s) (s âˆ© u) := by
    have : ContinuousOn (fderivWithin ğ•œ (fderivWithin ğ•œ f (s âˆ© u)) (s âˆ© u)) (s âˆ© u) :=
      ((hu.fderivWithin h'u (m := 1) (le_minSmoothness.trans hm)).fderivWithin h'u
      (m := 0) le_rfl).continuousOn
    apply this.congr
    intro y hy
    apply fderivWithin_fderivWithin_eq_of_eventuallyEq
    filter_upwards [u_open.mem_nhds hy.2] with z hz
    change (z âˆˆ s) = (z âˆˆ s âˆ© u)
    simp_all
  have B : Tendsto (fun k â†¦ fderivWithin ğ•œ (fderivWithin ğ•œ f s) s (y k)) atTop
      (ğ“ (fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x)) := by
    have : Tendsto y atTop (ğ“[s âˆ© u] x) := by
      apply tendsto_nhdsWithin_iff.2 âŸ¨y_lim, ?_âŸ©
      filter_upwards [L] with k hk using âŸ¨interior_subset (hy k), hkâŸ©
    exact (A x âŸ¨h'x, xuâŸ© ).tendsto.comp this
  have C (v w : E) : Tendsto (fun k â†¦ fderivWithin ğ•œ (fderivWithin ğ•œ f s) s (y k) v w) atTop
      (ğ“ (fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x v w)) := by
    have : Continuous (fun (A : E â†’L[ğ•œ] E â†’L[ğ•œ] F) â†¦ A v w) := by fun_prop
    exact (this.tendsto _).comp B
  have C' (v w : E) : Tendsto (fun k â†¦ fderivWithin ğ•œ (fderivWithin ğ•œ f s) s (y k) w v) atTop
      (ğ“ (fderivWithin ğ•œ (fderivWithin ğ•œ f s) s x v w)) := by
    apply (C v w).congr'
    filter_upwards [I] with k hk using hk v w
  intro v w
  exact tendsto_nhds_unique (C v w) (C' w v)

end IsRCLikeNormedField
